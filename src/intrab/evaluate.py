import os
from pathlib import Path
import nibabel as nib
import numpy as np
from nneval.evaluate_semantic import semantic_evaluation

def get_imgs_gts(dataset_dir):
    imgs_gts = {"Tr": [], "Ts": []}
    for suffix in ["Tr", "Ts"]:
        images_dir = os.path.join(dataset_dir, "images" + suffix)
        labels_dir = os.path.join(dataset_dir, "labels" + suffix)
        if os.path.exists(images_dir):
            imgs_gts[suffix].extend(
                [
                    (
                        os.path.join(images_dir, img_path),
                        os.path.join(labels_dir, img_path.removesuffix("_0000.nii.gz") + ".nii.gz"),
                    )
                    for img_path in os.listdir(images_dir)  # Adjust the extension as needed
                    # if os.path.exists(os.path.join(labels_dir, img_path.removesuffix('_0000.nii.gz') + '.nii.gz')) # Remove check. All the files should exist.
                ]
            )

    return imgs_gts

def write_binarised_gts(dataset_dir: Path, binarised_gts_dir: Path, targets_dict: dict[str, int]) -> None:
    """
    Given a dataset directory and an output_dir, binarises ground truths based upon a dictionary of targets of relevance, and sorts and stores them in a created subdirectory of output_dir
    """
    # Obtain imgs_gts; only gts are of interest
    imgs_gts = get_imgs_gts(dataset_dir)

    # Main loop
    for split in ['Tr', 'Ts']:
        for _, gt_path in imgs_gts[split]:
            gt_nib = nib.load(gt_path)
            gt = gt_nib.get_fdata()

            for target, label in targets_dict.items():
                # Create directory for gts binarised to this target
                target_dir = binarised_gts_dir / target
                target_dir.mkdir(exist_ok=True)

                # Binarise and save gt to appropriate folder
                gt_binarised = np.where(gt == label, 1, 0)
                gt_binarised = nib.Nifti1Image(gt_binarised.astype(np.float32), gt_nib.affine)
                gt_binarised.to_filename(target_dir / os.path.basename(gt_path))

    return 

if __name__ == '__main__':
    dataset_dir = Path('/home/t722s/Desktop/Datasets/Dataset350_AbdomenAtlasJHU_2img')
    results_dir = Path('/home/t722s/Desktop/ExperimentResults/metric_testing/')
    
    targets_dict = {'kidney_left': 3}

    exp_names = ['bbox3d_sliced', 'bounding_boxes', 'box_interpolation']

    # Write binarised gts to disk
    binarised_gts_parent_dir = results_dir / '_binarised_gts'
    binarised_gts_parent_dir.mkdir(exist_ok = True)
    write_binarised_gts(dataset_dir, binarised_gts_parent_dir, targets_dict)

    # Calculate metrics per experiment and per target
    for exp_name in exp_names:
        for target in targets_dict.keys():
            exp_target_dir = results_dir / exp_name / target # Segmetnations generated by this experiment for this target
            binarised_gt_dir = binarised_gts_parent_dir / target
            semantic_evaluation(semantic_pd_path = exp_target_dir, semantic_gt_path=binarised_gt_dir, 
                                output_path= exp_target_dir, classes_of_interest = (1,)) # classes_of_interests hardcoded to 1 sicne both the segmentation and the gt are now binary




