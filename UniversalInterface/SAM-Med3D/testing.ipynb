{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "join = os.path.join\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import torch\n",
    "from segment_anything.build_sam3D import sam_model_registry3D\n",
    "from segment_anything.utils.transforms3D import ResizeLongestSide3D\n",
    "from segment_anything import sam_model_registry\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import SimpleITK as sitk\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "import pickle\n",
    "from utils.click_method import get_next_click3D_torch_ritm, get_next_click3D_torch_2\n",
    "import utils.data_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set seed as 2023\n"
     ]
    }
   ],
   "source": [
    "# hardcode for juptyer notebook compatability\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    test_data_path = '/home/t722s/Desktop/Datasets/BratsTestData/',\n",
    "    checkpoint_path=  '',\n",
    "    results_save_path='/home/t722s/Desktop/Sam-Med3DTest/evalBrats/',\n",
    "    model='SAM-Med3D',\n",
    "    seed=2023,\n",
    "    dim = 3,\n",
    "    crop_size = 128,\n",
    "    data_type = 'Ts',\n",
    "    split_num = 1,\n",
    "    split_idx = 0,\n",
    ")\n",
    "\n",
    "points_path = os.path.join(args.results_save_path, 'prompts.pkl')\n",
    "\n",
    "SEED = args.seed\n",
    "print(\"set seed as\", SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(utils.data_loader)\n",
    "Dataset_Union_ALL_Val = utils.data_loader.Dataset_Union_ALL_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t722s/Desktop/Datasets/BratsTestData/imagesTs/BraTS2021_01646.nii.gz\n",
      "TESTING: 3d points for image 1 label 1 are:[(70, 82, 55), (50, 42, 76), (71, 72, 69), (76, 69, 67), (68, 69, 62)]\n"
     ]
    }
   ],
   "source": [
    "# Obtain dataloaders\n",
    "infer_transform = [\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad(mask_name='points', target_shape=(args.crop_size,args.crop_size,args.crop_size)), # Will center the cropping/padding at the center of the bounding box of the clicks supplied.\n",
    "]\n",
    "\n",
    "test_dataset = Dataset_Union_ALL_Val(\n",
    "    paths=args.test_data_path, \n",
    "    mode=\"Val\", \n",
    "    dim = 3,\n",
    "    label = 1,\n",
    "    points_path = points_path,\n",
    "    data_type=args.data_type, \n",
    "    transform=tio.Compose(infer_transform),\n",
    "    threshold=0,\n",
    "    split_num=args.split_num,\n",
    "    split_idx=args.split_idx,\n",
    "    pcc=False,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    sampler=None,\n",
    "    batch_size=1, \n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = ['/home/t722s/Desktop/Datasets/BratsTestData/imagesTs/BraTS2021_01646.nii.gz']\n",
    "dim = 3\n",
    "label = 1\n",
    "\n",
    "with open(points_path, 'rb') as f:\n",
    "    points_dict = pickle.load(f)\n",
    "\n",
    "index = 0\n",
    "\n",
    "tio_image = tio.ScalarImage.from_sitk(sitk.ReadImage(image_paths[index]))\n",
    "\n",
    "#### UNDER CONSTRUCTION\n",
    "# Load in points for this image and change to a mask to be usable by torchio\n",
    "points = points_dict[os.path.basename(image_paths[index])][label][str(dim) + 'D']\n",
    "points_mask = np.zeros(tio_image.shape[1:]) # Skip the color channel for now; reintroduce in label_map definition\n",
    "points_mask[*points.T] = 1\n",
    "\n",
    "points_mask = tio.LabelMap(tensor = torch.from_numpy(points_mask).float().unsqueeze(0), affine = tio_image.affine)\n",
    "\n",
    "subject = tio.Subject(\n",
    "    image = tio_image,\n",
    "    points_mask = points_mask\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universalModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
