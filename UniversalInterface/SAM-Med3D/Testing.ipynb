{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39, 39, 39, ..., 85, 85, 85]),\n",
       " array([38, 39, 39, ..., 73, 73, 73]),\n",
       " array([64, 63, 64, ..., 69, 70, 71]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08942b8b31f4415b8112a0146638ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90923738eb8f48ed93fe0af7b9d5d002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving prompts to /home/t722s/Desktop/Sam-Med3DTest/evalBrats/prompts.pkl\n"
     ]
    }
   ],
   "source": [
    "test_data_path = '/home/t722s/Desktop/Datasets/BratsMini/'\n",
    "res_path = '/home/t722s/Desktop/Sam-Med3DTest/evalBrats/'\n",
    "n_clicks = 5\n",
    "\n",
    "# Obtain test image and label paths. Only take those test images that have a label given\n",
    "labels_dir = os.path.join(test_data_path, 'labelsTs')\n",
    "test_label_paths = [os.path.join(labels_dir, label) for label in os.listdir(labels_dir)]\n",
    "test_image_paths = [label_path.replace('labels', 'images') for label_path in test_label_paths]\n",
    "\n",
    "# Obtain labels dictionary from dataset metadata\n",
    "dataset_metadata_file = os.path.join(test_data_path, 'dataset.json')\n",
    "\n",
    "with open(dataset_metadata_file, 'r') as f:\n",
    "    dataset_metadata = json.load(f)\n",
    "\n",
    "labels_dict = dataset_metadata['labels']\n",
    "fg_labels_dict = {k:int(v) for k, v in labels_dict.items() if int(v) != 0} # Reverse order since it's name -> int in the dataset.json\n",
    "\n",
    "# Create (point) prompts to use for each image and each fg label. \n",
    "# Two types: 2D: n_clicks points sampled uniformly at random per slice with foreground, 0 clicks per slice with no foreground; 3D: n_clicks sampled uniformly at random from the foreground region of the volume\n",
    "full_prompt_dict = {}\n",
    "\n",
    "for gt_mask_path in tqdm(test_label_paths):\n",
    "    gt_mask = sitk.GetArrayFromImage(sitk.ReadImage(gt_mask_path))\n",
    "    prompt_dict = defaultdict(dict) # For storing the prompts (per label and for 2D and 3D) for this particular image\n",
    "\n",
    "    # proceed through labels\n",
    "    for organ, label in tqdm(fg_labels_dict.items()):\n",
    "        volume_fg = np.where(gt_mask == label) # Get foreground indices as three lists\n",
    "        volume_fg = tuple(arr.astype(int) for arr in volume_fg) \n",
    "\n",
    "        n_fg_voxels = len(volume_fg[0])\n",
    "\n",
    "        if n_fg_voxels == 0:\n",
    "            tqdm.write(f'WARNING: Mask {gt_mask_path} is missing a segmentation for {organ}. An empty prompt list will be supplied')\n",
    "            prompt_dict[label]['3D'] = np.array([])\n",
    "            prompt_dict[label]['2D'] = np.array([])\n",
    "            continue\n",
    "\n",
    "        fg_slices = np.unique(volume_fg[0]) # Obtain superior axis slices which have foreground before reformating indices\n",
    "\n",
    "\n",
    "        # 3D point generation:\n",
    "        try: \n",
    "            point_indices = np.random.choice(len(volume_fg[0]), size = n_clicks, replace = False)\n",
    "        except ValueError:\n",
    "            raise RuntimeError(f'More points were requested than the number of foreground pixels in the volume ({n_clicks} vs {n_fg_voxels})')\n",
    "\n",
    "\n",
    "        points3D = [(volume_fg[0][idx], volume_fg[1][idx], volume_fg[2][idx]) for idx in point_indices] # change from triple of arrays format to list of triples format\n",
    "        prompt_dict[label]['3D'] = np.array(points3D)\n",
    "\n",
    "\n",
    "        # 2D point generation:\n",
    "        points2D = []\n",
    "        warning_zs = {} # tracks slices without enough foreground, if any should exist\n",
    "\n",
    "        for slice_index in fg_slices:\n",
    "            slice_fg = np.where(gt_mask[slice_index,:,:] == label)\n",
    "            slice_fg = tuple(arr.astype(int) for arr in slice_fg) \n",
    "\n",
    "            n_fg_pixels = len(slice_fg[0])\n",
    "            if n_fg_pixels >= n_clicks:\n",
    "                point_indices = np.random.choice(n_fg_pixels, size = n_clicks, replace = False)\n",
    "            else:\n",
    "                # In this case, take all foreground pixels and then obtain some duplicate points by sampling with replacement additionally\n",
    "                warning_zs[f'z = {slice_index}'] = n_fg_pixels\n",
    "                point_indices = np.concatenate([np.arange(n_fg_pixels),\n",
    "                                            np.random.choice(n_fg_pixels, size = n_clicks-n_fg_pixels, replace = True)])\n",
    "            \n",
    "            points2D.extend([(slice_index, slice_fg[0][idx], slice_fg[1][idx]) for idx in point_indices])\n",
    "\n",
    "        if warning_zs:\n",
    "            tqdm.write(f'WARNING: some slices in {gt_mask_path} had fewer than n_clicks = {n_clicks} foreground pixels. Specifically: {warning_zs}')\n",
    "\n",
    "        prompt_dict[label]['2D'] = np.array(points2D)\n",
    "\n",
    "    full_prompt_dict[os.path.basename(gt_mask_path)] = dict(prompt_dict)\n",
    "\n",
    "print(f'Saving prompts to {os.path.join(res_path, \"prompts.pkl\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universalModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
