{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nye0/SAM-Med2D/blob/main/predictor_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e574ca7",
      "metadata": {},
      "source": [
        "# SAMMed2D Comparison\n",
        "This notebook contains a stripped down version of the predictor_example.ipynb file from the SAMMed2D repo as well as code to implement my model and thus verify that they perform identically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e8492548",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change path to be one folder up to permit appropriate imports\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('..'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea65409b",
      "metadata": {},
      "source": [
        "## Environment Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "69b28288",
      "metadata": {
        "id": "69b28288"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67418df1",
      "metadata": {},
      "source": [
        "## Compare point-prompt based segmentations\n",
        "### Use extracted code from predictor_example.ipynb to generate a segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3c2e4f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c2e4f6b",
        "outputId": "16670f19-01ac-472c-f535-8f3bf4fdb767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "*******load /home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\n"
          ]
        }
      ],
      "source": [
        "# Example image\n",
        "image = cv2.imread('data_demo/images/amos_0507_31.png')\n",
        "\n",
        "# Load SAM-Med2D model\n",
        "from utils.SAMMed2D_segment_anything import sam_model_registry\n",
        "from utils.SAMMed2D_segment_anything.predictor_sammed import SammedPredictor\n",
        "from argparse import Namespace\n",
        "args = Namespace()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.image_size = 256\n",
        "args.encoder_adapter = True\n",
        "args.sam_checkpoint = \"/home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\"\n",
        "model = sam_model_registry[\"vit_b\"](args).to(device)\n",
        "predictor = SammedPredictor(model)\n",
        "\n",
        "# Process the image to produce an image embedding by calling `SammedPredictor.set_image`. `SammedPredictor` remembers this embedding and will use it for subsequent mask prediction.\n",
        "predictor.set_image(image)\n",
        "\n",
        "# Specifying a specific object with a point\n",
        "ori_h, ori_w, _ = image.shape\n",
        "input_point = np.array([[162, 127]])\n",
        "input_label = np.array([1])\n",
        "\n",
        "masks, scores, logits = predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    multimask_output=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f6168e",
      "metadata": {},
      "source": [
        "### Now generate the same segmentation using code from this package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7948f44a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7948f44a",
        "outputId": "25d0b67a-8fd9-4140-9f98-3235caad04db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "*******load /home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Performing inference on slices: 100%|██████████| 1/1 [00:00<00:00, 26.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arrays equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from classes.SAMMed2DClass import SAMMed2DInferer\n",
        "from utils.base_classes import Points\n",
        "\n",
        "# Load Model\n",
        "device = 'cuda'\n",
        "checkpoint_path = \"/home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\"\n",
        "inferer = SAMMed2DInferer(checkpoint_path, device)\n",
        "\n",
        "\n",
        "# My model takes 3d grayscale images, so take the image, remove the color dimension and give it a z dimension\n",
        "img_path = \"data_demo/images/amos_0507_31.png\"\n",
        "img_2d = cv2.imread(img_path)\n",
        "img_3d = img_2d[:,:,0][None]\n",
        "\n",
        "\n",
        "# Obtain same prompt as in demo\n",
        "input_point = np.array([162, 127])\n",
        "input_point_3d = np.concatenate([input_point, [0]]) # include a z dimension for the point\n",
        "input_point_3d = input_point_3d[::-1] # Reverse order so xyz->zyx\n",
        "input_point_3d = input_point_3d[None] # Give N dimension\n",
        "input_label = np.array([1])\n",
        "\n",
        "prompt = Points(coords = input_point_3d, labels = input_label)\n",
        "\n",
        "# Segment\n",
        "segmentation = inferer.predict(img_3d, prompt)\n",
        "\n",
        "# Convert back to 2d to compare with original code and verify equality\n",
        "seg_2d = segmentation[0] # Select slice for z=0\n",
        "seg_original = masks[0] # Select first mask (only one mask returned in this case; look at comment)\n",
        "\n",
        "print(f'Arrays equal? {np.array_equal(seg_2d, seg_original)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e2d5a9",
      "metadata": {
        "id": "41e2d5a9"
      },
      "source": [
        "## Compare boxes\n",
        "### From predictor_example.ipynb:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ea92a7b",
      "metadata": {
        "id": "8ea92a7b"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('data_demo/images/s0114_111.png')\n",
        "predictor.set_image(image)\n",
        "input_box = np.array([89,43,113,64]) #\n",
        "\n",
        "masks, _, _ = predictor.predict(\n",
        "    point_coords=None,\n",
        "    point_labels=None,\n",
        "    box=input_box,\n",
        "    multimask_output=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b1417f",
      "metadata": {},
      "source": [
        "## From this package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c2d3a357",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using previously generated image embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Performing inference on slices: 100%|██████████| 1/1 [00:00<00:00, 25.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Arrays equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from utils.base_classes import Boxes\n",
        "\n",
        "# Make image 3d grayscale\n",
        "img_path = \"data_demo/images/s0114_111.png\"\n",
        "img_2d = cv2.imread(img_path)\n",
        "img_3d = img_2d[:,:,0][None]\n",
        "\n",
        "# Obtain prompt\n",
        "input_box = np.array([89,43,113,64])\n",
        "prompt = Boxes({0:input_box})\n",
        "\n",
        "# Segment\n",
        "segmentation = inferer.predict(img_3d, prompt)\n",
        "\n",
        "## Convert back to 2d to compare with original code and verify equality\n",
        "seg_2d = segmentation[0]\n",
        "seg_original = masks[0]\n",
        "\n",
        "print(f'Arrays equal? {np.array_equal(seg_2d, seg_original)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
