{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "*******load /home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating down: 100%|██████████| 22/22 [00:01<00:00, 19.16it/s]\n",
      "Propagating up: 100%|██████████| 22/22 [00:01<00:00, 20.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8177772392806715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating down: 100%|██████████| 22/22 [00:00<00:00, 73.20it/s]\n",
      "Propagating up: 100%|██████████| 22/22 [00:00<00:00, 73.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8263593581674888\n",
      "0.8269173423455405\n",
      "0.8302757994359734\n",
      "0.8294789514803222\n",
      "0.8293258507806317\n",
      "degrees of freedom bound met; terminating with performance 0.8293258507806317\n"
     ]
    }
   ],
   "source": [
    "# Get initial segmentation\n",
    "from classes.SAMMed2DClass_unstable import SAMMed2DInferer\n",
    "from utils.base_classes import Points\n",
    "import torch\n",
    "\n",
    "import utils.analysisUtils as anUt\n",
    "import utils.promptUtils as prUt\n",
    "from utils.imageUtils import read_im_gt\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.interactivity import gen_contour_fp_scribble\n",
    "\n",
    "# Obtain model, image, gt\n",
    "device = 'cuda'\n",
    "sammed2d_checkpoint_path = \"/home/t722s/Desktop/UniversalModels/TrainedModels/sam-med2d_b.pth\"\n",
    "sammed2d_inferer = SAMMed2DInferer(sammed2d_checkpoint_path, device)\n",
    "\n",
    "img_path = '/home/t722s/Desktop/Datasets/Dataset350_AbdomenAtlasJHU_2img/imagesTr/BDMAP_00000001_0000.nii.gz'\n",
    "gt_path = '/home/t722s/Desktop/Datasets/Dataset350_AbdomenAtlasJHU_2img/labelsTr/BDMAP_00000001.nii.gz'\n",
    "img, gt = read_im_gt(img_path, gt_path, 3)\n",
    "\n",
    "# Obtain initial segmentation\n",
    "# Experiment: Point propagation\n",
    "\n",
    "seed = 11121\n",
    "n_clicks = 5\n",
    "\n",
    "# Get seed prompt and bounds\n",
    "seed_point = prUt.get_seed_point(gt, n_clicks, seed)\n",
    "slices_to_infer = np.where(np.any(gt, axis=(1,2)))[0]\n",
    "\n",
    "segmentation, all_prompts = prUt.point_propagation(sammed2d_inferer, img, seed_point, slices_to_infer, seed, n_clicks)\n",
    "print(anUt.compute_dice(gt,segmentation))\n",
    "\n",
    "anUt.compute_dice(segmentation, gt)\n",
    "\n",
    "\n",
    "with open('/home/t722s/Desktop/test/test_segjhu10.pkl', 'wb') as f:\n",
    "    pickle.dump(segmentation, f)\n",
    "\n",
    "with open('/home/t722s/Desktop/test/test_segjhu10.pkl', 'rb') as f:\n",
    "    segmentation = pickle.load(f)\n",
    "segmentation, prompt = prUt.point_propagation(sammed2d_inferer, img, seed_point, slices_to_infer, seed, n_clicks)\n",
    "condition = 'dof'\n",
    "dof_bound = 60\n",
    "perf_bound = 1 # Place holder, only needed when condition = 'perf'\n",
    "init_dof = 5\n",
    "contour_distance = 2\n",
    "disk_size_range = (0,0)\n",
    "scribble_length = 0.3\n",
    "\n",
    "\n",
    "# Initialise low res masks to provide for interactivity\n",
    "verbosity = sammed2d_inferer.verbose \n",
    "sammed2d_inferer.verbose = False\n",
    "dof = init_dof\n",
    "slices_inferred = np.unique(prompt.value['coords'][:,0])\n",
    "low_res_masks = sammed2d_inferer.slice_lowres_dict.copy()\n",
    "low_res_masks = {k:torch.sigmoid(v).squeeze().cpu().numpy() for k,v in low_res_masks.items()}\n",
    "max_fp_slices = []\n",
    "has_generated_positive_prompt = False\n",
    "\n",
    "prompts = [prompt]\n",
    "segmentations = [segmentation]\n",
    "dice_scores = [prUt.compute_dice(segmentation, gt)]\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Determine whether to give positive prompts or attempt negative prompt\n",
    "    fn_mask = (segmentation == 0) & (gt == 1)\n",
    "    fn_count = np.sum(fn_mask)\n",
    "\n",
    "    fg_count = np.sum(segmentation)\n",
    "\n",
    "    generate_positive_prompts_prob = fn_count/fg_count # Generate positive prompts when much of the foreground isn't segmented\n",
    "    generate_positive_prompts = np.random.binomial(1,generate_positive_prompts_prob)\n",
    "\n",
    "    if not generate_positive_prompts:\n",
    "        # Obtain contour scribble on worst sagittal slice\n",
    "        fp_mask = (segmentation == 1) & (gt == 0)\n",
    "        axis = 1\n",
    "        fp_sums = np.sum(fp_mask, axis=tuple({0,1,2} - {axis}))\n",
    "        max_fp_idx = np.argmax(fp_sums)\n",
    "        max_fp_slice = gt[:, max_fp_idx]\n",
    "        max_fp_slices.append(max_fp_slice)\n",
    "        slice_seg = segmentation[:, max_fp_idx]\n",
    "\n",
    "        scribble = gen_contour_fp_scribble(gt[:, max_fp_idx], slice_seg, contour_distance, disk_size_range, scribble_length)\n",
    "        if scribble is None:\n",
    "            generate_positive_prompts = 1 # Generate positive prompts instead\n",
    "        else: \n",
    "            scribble_coords = np.where(scribble)\n",
    "            scribble_coords = np.stack(scribble_coords, axis = 1)\n",
    "\n",
    "            # Obtain false positive points and make new prompt\n",
    "            is_fp_mask = slice_seg[*scribble_coords.T].astype(bool)\n",
    "            fp_coords = scribble_coords[is_fp_mask]\n",
    "\n",
    "            ## Position fp_coords back into original 3d coordinate system\n",
    "            missing_axis = np.repeat(max_fp_idx, len(fp_coords))\n",
    "            fp_coords_3d = np.vstack([fp_coords[:,0], missing_axis, fp_coords[:,1]]).T\n",
    "            improve_slices = fp_coords_3d[:,0]\n",
    "            dof += 3*4 # To dicuss: assume drawing a scribble is as difficult as drawing four points\n",
    "\n",
    "            ## Add to old prompt\n",
    "            coords = np.concatenate([prompt.value['coords'], fp_coords_3d], axis = 0)\n",
    "            labels = np.concatenate([prompt.value['labels'], [0]*len(fp_coords_3d)])\n",
    "            prompt = Points(value = {'coords': coords, 'labels': labels})\n",
    "\n",
    "            ## Subset to prompts only on the slices with new prompts\n",
    "            coords, labels = prompt.value.values()\n",
    "            fix_slice_mask = np.isin(prompt.value['coords'][:,0], improve_slices)\n",
    "            new_prompt = Points({'coords': coords[fix_slice_mask], 'labels': labels[fix_slice_mask]})\n",
    "\n",
    "    if generate_positive_prompts:\n",
    "        if not has_generated_positive_prompt: \n",
    "            dof+=6 # If first time generating positive prompts, generate a bottom and top point, taking 4 degrees of freedom: (4 dof even though there are 6 coordinates since the coordinate of the lowest and highest slice is fixed) \n",
    "            bottom_seed_prompt, _, top_seed_prompt = prUt.get_fg_points_from_cc_centers(gt, 3)\n",
    "            has_generated_positive_prompt = True\n",
    "\n",
    "        # Find fp coord from the middle axial range of the image\n",
    "        lower, upper = np.percentile(slices_inferred, [30, 70 ])\n",
    "        fp_coords = np.vstack(np.where(fn_mask)).T\n",
    "        middle_mask = (lower < fp_coords[:, 0]) & (fp_coords[:,0] < upper) # Mask to determine which false negatives lie between the 30th to 70th percentile\n",
    "        if np.sum(middle_mask) == 0:\n",
    "            middle_mask = np.ones(len(fp_coords), bool) # If there are no false negatives in the middle, draw from all coordinates (unlikely given that there must be many)\n",
    "        fp_coords = fp_coords[middle_mask, :]\n",
    "        new_middle_seed_prompt = fp_coords[np.random.choice(len(fp_coords), 1)]\n",
    "        dof += 3\n",
    "\n",
    "        # Obtain top and bottom prompts and then interpolate a line of coordinates in between\n",
    "        new_seed_prompt = np.vstack([bottom_seed_prompt, new_middle_seed_prompt, top_seed_prompt])\n",
    "        new_coords =  prUt.interpolate_points(new_seed_prompt, kind = 'linear').astype(int)\n",
    "\n",
    "        # Add to old prompt\n",
    "        coords = np.concatenate([prompt.value['coords'], new_coords], axis = 0)\n",
    "        labels = np.concatenate([prompt.value['labels'], [1]*len(new_coords)])\n",
    "        new_prompt = Points(value = {'coords': coords, 'labels': labels})\n",
    "        improve_slices = slices_inferred # improve all slices\n",
    "\n",
    "    # Generate new segmentation and integrate into old one\n",
    "    new_seg = sammed2d_inferer.predict(img, new_prompt)\n",
    "    prompts.append(new_prompt)\n",
    "    segmentation[improve_slices] = new_seg[improve_slices]\n",
    "    segmentations.append(segmentation.copy())\n",
    "    # Update the dictionary\n",
    "    low_res_masks.update({fix_slice_idx: torch.sigmoid(sammed2d_inferer.slice_lowres_dict[fix_slice_idx]).squeeze().cpu().numpy() for fix_slice_idx in improve_slices})\n",
    "    dice_scores = [prUt.compute_dice(segmentation, gt)]\n",
    "    print(dice_scores[-1])\n",
    "\n",
    "    # Check break conditions\n",
    "    if condition == 'dof' and dof >= dof_bound:\n",
    "        print(f'degrees of freedom bound met; terminating with performance {dice_scores[-1]}')\n",
    "        break\n",
    "    elif condition == 'perf' and dice_scores[-1] >= perf_bound:\n",
    "        print(f'performance bound met; terminating with performance {dice_scores[-1]}')\n",
    "        break\n",
    "    elif condition == 'perf' and len(dice_scores) == 10:\n",
    "        print(f'Could not achieve desired performance within 10 steps; terminating with performance {dice_scores[-1]}')\n",
    "\n",
    "sammed2d_inferer.verbose = verbosity # return verbosity to initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144, 145, 178],\n",
       "       [148, 145, 173],\n",
       "       [147, 145, 174],\n",
       "       [146, 145, 167],\n",
       "       [148, 145, 170],\n",
       "       [143, 145, 162],\n",
       "       [146, 145, 176],\n",
       "       [146, 145, 182],\n",
       "       [145, 145, 164],\n",
       "       [145, 145, 176],\n",
       "       [148, 145, 172],\n",
       "       [144, 145, 180],\n",
       "       [144, 145, 177],\n",
       "       [147, 145, 170],\n",
       "       [146, 145, 166],\n",
       "       [146, 145, 169],\n",
       "       [146, 145, 175],\n",
       "       [146, 145, 181],\n",
       "       [148, 145, 171],\n",
       "       [144, 145, 179],\n",
       "       [146, 145, 165],\n",
       "       [146, 145, 168],\n",
       "       [146, 145, 174],\n",
       "       [146, 145, 183],\n",
       "       [144, 145, 163],\n",
       "       [145, 145, 180]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = [p.value['coords'] for p in prompts]\n",
    "\n",
    "def find_new_rows(coords):\n",
    "    \"\"\"\n",
    "    Generates a list of arrays, where each array contains rows from t[i] \n",
    "    that are not present in t[i-1].\n",
    "\n",
    "    Args:\n",
    "    t (list of np.array): A list of m nx3 numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "    list of np.array: A list of length m-1, where each entry contains rows\n",
    "                      from t[i] that are not in t[i-1].\n",
    "    \"\"\"\n",
    "    diffs = []\n",
    "    for i in range(1, len(coords)):\n",
    "        # Convert arrays to sets of tuples for comparison\n",
    "        set_prev = set(map(tuple, coords[i-1]))\n",
    "        set_curr = set(map(tuple, coords[i]))\n",
    "        \n",
    "        # Find difference and convert it back to an array\n",
    "        new_rows = np.array(list(set_curr - set_prev))\n",
    "        diffs.append(new_rows)\n",
    "    \n",
    "    return diffs\n",
    "\n",
    "t = find_new_rows(coords)\n",
    "t[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise\n",
    "plt.figure(figsize = (13,13))\n",
    "plt.imshow(max_fp_slice, cmap = 'gray')\n",
    "show_mask(slice_seg, plt.gca())\n",
    "# contour_rounded = np.round(contour).astype(int)\n",
    "# plt.scatter(contour_rounded[:,1], contour_rounded[:,0], c= 'green', s = 10)\n",
    "plt.scatter(scribble_coords[:,1], scribble_coords[:,0], c = 'red', s = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in segmentations:\n",
    "    # Visualise\n",
    "    plt.figure(figsize = (13,13))\n",
    "    plt.imshow(max_fp_slice, cmap = 'gray')\n",
    "    show_mask(slice_seg, plt.gca())\n",
    "    # contour_rounded = np.round(contour).astype(int)\n",
    "    # plt.scatter(contour_rounded[:,1], contour_rounded[:,0], c= 'green', s = 10)\n",
    "    plt.scatter(scribble_coords[:,1], scribble_coords[:,0], c = 'red', s = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universalModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
