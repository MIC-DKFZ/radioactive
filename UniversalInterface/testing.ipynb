{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchio as tio\n",
    "from torchio.data.io import sitk_to_nib\n",
    "import SimpleITK as sitk\n",
    "import napari\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from utils.image import read_im_gt, read_reorient_nifti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = '/home/t722s/Desktop/Datasets/Dataset350_AbdomenAtlasJHU_2img/imagesTr/BDMAP_00000001_0000.nii.gz'\n",
    "gt_path = '/home/t722s/Desktop/Datasets/Dataset350_AbdomenAtlasJHU_2img/labelsTr/BDMAP_00000001.nii.gz'\n",
    "class_label = 3\n",
    "\n",
    "gt_unprocessed = nib.load(gt_path).get_fdata()\n",
    "gt_unprocessed = np.where(gt_unprocessed == class_label, 1, 0)\n",
    "\n",
    "img, gt = read_im_gt(img_path, gt_path, class_label, RAS=True)\n",
    "\n",
    "gt_2, _ = read_reorient_nifti(gt_path, np.float32, RAS = True)\n",
    "gt_2 = np.where(gt_2 == 3, 1, 0)\n",
    "\n",
    "np.array_equal(gt, gt_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_reorient contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gt_path\n",
    "dtype = np.float32\n",
    "RAS = True\n",
    "img = nib.load(path)\n",
    "img_ras = img # Initialize variables to hold potentially reoriented images\n",
    "# Check if gt, image are already in RAS+ \n",
    "if nib.aff2axcodes(img_ras.affine) != ('R', 'A', 'S'):\n",
    "    img_ras = nib.as_closest_canonical(img)\n",
    "\n",
    "img_data = img_ras.get_fdata().astype(dtype)\n",
    "\n",
    "if not RAS:\n",
    "    img_data = img_data.transpose(2,1,0) # change from RAS to row-major ie xyz to zyx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_im_gt contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAS = True\n",
    "\n",
    "img, gt = nib.load(img_path), nib.load(gt_path)\n",
    "img_ras, gt_ras = img, gt  # Initialize variables to hold potentially reoriented images\n",
    "\n",
    "# Check if gt, image are already in RAS+ \n",
    "if nib.aff2axcodes(img.affine) != ('R', 'A', 'S'):\n",
    "    img_ras = nib.as_closest_canonical(img)\n",
    "\n",
    "if nib.aff2axcodes(gt.affine) != ('R', 'A', 'S'):\n",
    "    gt_ras = nib.as_closest_canonical(gt)\n",
    "\n",
    "img_data = img_ras.get_fdata().astype(np.float32)\n",
    "gt_data = gt_ras.get_fdata().astype(int)\n",
    "\n",
    "# Ensure organ is binary\n",
    "if organ_label is None:\n",
    "    flat_data = gt_data.ravel()\n",
    "    if not np.all( (flat_data == 0) | (flat_data == 1)):\n",
    "        raise ValueError('Ground truth is not binary and no foreground label to subset to is specified')\n",
    "    \n",
    "else:\n",
    "    gt_data = (gt_data == organ_label).astype(int)\n",
    "\n",
    "if not RAS:\n",
    "    img_data, gt_data = img_data.transpose(2,1,0), gt_data.transpose(2,1,0) # change from RAS to row-major ie xyz to zyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(gt, gt_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universalModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
