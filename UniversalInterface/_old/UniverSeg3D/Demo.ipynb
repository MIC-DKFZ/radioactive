{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import torch\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import einops as E\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys.path.append('/home/t722s/Desktop/UniversalModels/OtherRepos/UniverSeg')\n",
    "from universeg import universeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_volume(volume_path, fg_label = None, sizeXY = (128,128)):\n",
    "    '''\n",
    "    Given a path to a nifti volume, read it in, discarding everything but specified fg_label and resizing. Returns as a numpy array\n",
    "    '''\n",
    "    volume = nib.load(volume_path).get_fdata()\n",
    "    if fg_label: # If is a label, set all other entries to 0. Mostly useful for multisegmentation datasets. \n",
    "        volume = np.where(volume == fg_label, volume, 0) # same as volume[volume!=fg_label] = 0, but faster. Could be even faster to use gpu, but I'm not sure about the switching back and forth.\n",
    "\n",
    "    return(volume)\n",
    "\n",
    "def _classify_list(l, delta = 3):\n",
    "    '''\n",
    "    Given a list of 1s and 0s (ie slices with foreground, slices with no foreground within a volume), return list of equal length classifying each element as 'bg', 'bgb', 'fgb' and 'fg', meaning background, background border, foreground border\n",
    "    and foreground, with 'background border' meaning a 0 within delta of a 1, and similarly for 'foreground border'\n",
    "    '''\n",
    "\n",
    "    n = len(l)\n",
    "    classification = [''] * n\n",
    "\n",
    "    for i in range(n):\n",
    "        # Check if within delta indices, there's an element of the other type\n",
    "        lower = max(i-delta, 0)\n",
    "        upper = min(i+delta+1, n)\n",
    "        \n",
    "        is_border = any(l[j] != l[i] \n",
    "                        for j in range(lower, upper))\n",
    "\n",
    "        if l[i] == 1:\n",
    "            classification[i] = 'fgb' if is_border else 'fg'\n",
    "        else:\n",
    "            classification[i] = 'bgb' if is_border else 'bg'\n",
    "\n",
    "    return classification  \n",
    "\n",
    "def get_support_inds(label, num_of_slices = [1,1,1,1]): \n",
    "    '''\n",
    "    Given a label volume, gets uniformly sampled slices for each class (background, background-border, foreground-border, foreground) to use as indices for support slices. The number per class is defind by\n",
    "    num_of_slices, representing the desired number of support slices from background, background border, foreground border and foreground respectively. Returns a list of slices\n",
    "    '''\n",
    "    fg_present = np.any(label!=0, axis = (0,1)) # Find slices containing foreground\n",
    "\n",
    "    fg_present_nuanced = _classify_list(fg_present)\n",
    "\n",
    "    support_inds = []\n",
    "\n",
    "    for i, cls in enumerate(['bg', 'bgb', 'fgb', 'fg']):\n",
    "        n = num_of_slices[i]\n",
    "\n",
    "        # Sample n indices uniformly at random of type cls from l \n",
    "        cls_inds = [i for i, x in enumerate(fg_present_nuanced)  if x == cls] # ie the slice indices of type cls\n",
    "\n",
    "        if n > fg_present_nuanced.count(cls):\n",
    "            raise RuntimeError(f'Not enough slices of type {cls}')\n",
    "        \n",
    "        sampled_inds = random.sample(cls_inds, n)\n",
    "\n",
    "        support_inds.extend(sampled_inds)\n",
    "\n",
    "    return(support_inds)\n",
    "\n",
    "def get_support_slices_and_labels(support_volume_paths, support_label_paths, fg_label, num_of_slices = [1,1,1,1], sizeXY = [128,128], device = 'cuda'):# Include infer label option for binary tasks\n",
    "    '''\n",
    "    Given support volumes and labels paths, extracts slices to use as 2D support sets. The number of slices extracted per volume is given by num_of_slices, which also determines where the slices are taken from within the volume.\n",
    "    The paths in support_volume_paths and support_label_paths must correspond. Returns (support_slices, support_labels).\n",
    "    '''\n",
    "\n",
    "    if len(support_volume_paths) != len(support_label_paths):\n",
    "        raise RuntimeError(f'Unequal number of support volume paths and labels given, {len(support_volume_paths)}, {len(support_label_paths)} respectively')\n",
    "\n",
    "    support_slices = []\n",
    "    support_labels = []\n",
    "\n",
    "\n",
    "    # Obtain support slices and their labels\n",
    "    for i in range(len(support_volume_paths)):\n",
    "        # Load in volumes and labels as tuples of tensors\n",
    "        volume = read_volume(support_volume_paths[i])\n",
    "        label = read_volume(support_label_paths[i], fg_label = fg_label)\n",
    "\n",
    "        # Choose indices to use to select support slices and labels\n",
    "        support_inds = get_support_inds(label, num_of_slices)\n",
    "\n",
    "        # obtain support slices and labels from support volumes and labels as torch tensors. Reorient the dimensions since z isn't spatial anymore, but just indexing chosen slices (necessary for F.interpolate)\n",
    "        slices = torch.from_numpy(E.rearrange(volume[:, :, support_inds], 'x y z -> z x y')).unsqueeze(1)\n",
    "        labels = torch.from_numpy(E.rearrange(label[:, :, support_inds], 'x y z -> z x y')).unsqueeze(1)\n",
    "\n",
    "        # rescale here instead of after concatenation (ie so F.interpolate would only be called once) to allow for datasets with multiple volume dimensionalities, eg amos\n",
    "        if sizeXY:\n",
    "            # Minimum value will be kept, but maximum not\n",
    "            imgMin = torch.min(slices)\n",
    "\n",
    "            slices = F.interpolate(slices,\n",
    "                                    size = sizeXY,\n",
    "                                    mode = 'bicubic') # NOTE: unsure if I should use align_corners.\n",
    "            \n",
    "            slices = torch.clamp(slices, imgMin, float('inf'))\n",
    "\n",
    "            labels = F.interpolate(labels,\n",
    "                                    size = sizeXY,\n",
    "                                    mode = 'nearest')\n",
    "\n",
    "        support_slices.append(slices)\n",
    "        support_labels.append(labels)\n",
    "\n",
    "    support_slices = torch.from_numpy(np.concatenate(support_slices, axis = 0)).float() #.unsqueeze(0) not sure why I thoguht I needed this. Universeg? #concat along axis 0 and add explicit unidimensional color channel \n",
    "    support_labels = torch.from_numpy(np.concatenate(support_labels, axis = 0)).float()  #.unsqueeze(0)\n",
    "\n",
    "    return (support_slices, support_labels)\n",
    "\n",
    "def get_query_slices_and_labels(volume_path, label_path, fg_label, sizeXY = [128, 128]):# Include infer label option for binary tasks\n",
    "    '''\n",
    "    Given support volumes and labels paths, extracts slices to use as 2D support sets. The number of slices extracted per volume in the case support = True is given by num_of_slices, which also determines where the slices are taken from within the volume.\n",
    "    The paths in volume_paths and label_paths must correspond. Returns (support_slices, support_labels).\n",
    "    '''\n",
    "    volume = read_volume(volume_path)\n",
    "    label = read_volume(label_path, fg_label = fg_label)\n",
    "\n",
    "    # Reformat for rescaling and universeg\n",
    "    slices = torch.from_numpy(E.rearrange(volume, 'x y z -> z x y')).unsqueeze(1)\n",
    "    labels = torch.from_numpy(E.rearrange(label, 'x y z -> z x y')).unsqueeze(1)\n",
    "\n",
    "    if sizeXY:\n",
    "        # Minimum value will be kept, but maximum not\n",
    "        imgMin = torch.min(slices)\n",
    "\n",
    "        slices = F.interpolate(slices,\n",
    "                                size = sizeXY,\n",
    "                                mode = 'bicubic') # NOTE: unsure if I should use align_corners.\n",
    "        \n",
    "        slices = torch.clamp(slices, imgMin, float('inf'))\n",
    "\n",
    "        labels = F.interpolate(labels,\n",
    "                                size = sizeXY,\n",
    "                                mode = 'nearest')\n",
    "\n",
    "    return (slices.float(), labels.float())\n",
    "\n",
    "\n",
    "def dice_score(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    y_pred = y_pred.long()\n",
    "    y_true = y_true.long()\n",
    "    score = 2*(y_pred*y_true).sum() / (y_pred.sum() + y_true.sum())\n",
    "    return score.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference_scored(model, image, label, support_images, support_labels, device = 'cuda'):\n",
    "    image, label = image.to(device), label.to(device)\n",
    "\n",
    "    # inference\n",
    "    logits = model(\n",
    "        image[None],\n",
    "        support_images[None],\n",
    "        support_labels[None]\n",
    "    )[0] # outputs are logits        \n",
    "\n",
    "    soft_pred = torch.sigmoid(logits)\n",
    "    hard_pred = soft_pred.round().clip(0,1)\n",
    "\n",
    "    #  score\n",
    "    score = dice_score(hard_pred, label)\n",
    "\n",
    "    # return a dictionary of all relevant variables\n",
    "    return(score)\n",
    "\n",
    "def visualize_tensors(tensors, col_wrap=8, col_names=None, title=None):\n",
    "    M = len(tensors)\n",
    "    N = len(next(iter(tensors.values())))\n",
    "    \n",
    "    cols = col_wrap\n",
    "    rows = math.ceil(N/cols) * M\n",
    "\n",
    "    d = 2.5\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(d*cols, d*rows))\n",
    "    if rows == 1:\n",
    "      axes = axes.reshape(1, cols)\n",
    "    \n",
    "    for g, (grp, tensors) in enumerate(tensors.items()):\n",
    "        for k, tensor in enumerate(tensors):\n",
    "            col = k % cols\n",
    "            row = g + M*(k//cols)\n",
    "            x = tensor.detach().cpu().numpy().squeeze()\n",
    "            ax = axes[row,col]\n",
    "            if len(x.shape) == 2:\n",
    "                ax.imshow(x,vmin=0, vmax=1, cmap='gray', aspect = 'equal')\n",
    "            else:\n",
    "                ax.imshow(E.rearrange(x,'C H W -> H W C'))\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(grp, fontsize=16)\n",
    "            if col_names is not None and row == 0:\n",
    "                ax.set_title(col_names[col])\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            ax = axes[i,j]\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "    if title:\n",
    "        plt.suptitle(title, fontsize=20)\n",
    "            \n",
    "    plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN SCRIPT\n",
    "# Configurable parameters \n",
    "device = 'cuda'\n",
    "sizeXY = [256,256]\n",
    "\n",
    "# Obtain support slices\n",
    "volume_dir = '/home/t722s/Desktop/Datasets/amosForUniversegTest/imagesTr/'\n",
    "volume_paths = sorted([os.path.join(volume_dir, file) for file in os.listdir(volume_dir)]) # in later usage, if a random selection is desired, don't use sorted here, and use np.random.permutation later\n",
    "\n",
    "label_dir = '/home/t722s/Desktop/Datasets/amosForUniversegTest/labelsTr/'\n",
    "label_paths = sorted([os.path.join(label_dir, file) for file in os.listdir(label_dir)])\n",
    "# Split volumes, labels into support and query sets\n",
    "# volume_paths, label_paths = np.random.permutation(volume_paths), np.random.permutation(label_paths)\n",
    "n_support_volumes = 8 # There for num_of_slices = [a,b,c,d], there'll be n_support_volumes * (a+b+c+d) total support slices\n",
    "\n",
    "support_volume_paths,   query_volume_paths  = volume_paths[:n_support_volumes], volume_paths[n_support_volumes:]\n",
    "support_label_paths,    query_label_paths   = label_paths[:n_support_volumes],  label_paths[n_support_volumes:] \n",
    "\n",
    "support_slices, support_labels = get_support_slices_and_labels(support_volume_paths, support_label_paths, fg_label = 1, num_of_slices= [0,0,1,1], sizeXY = sizeXY)\n",
    "support_slices, support_labels = support_slices.to(device), support_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6921700bd24646f992c3406fc559d3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "query_slices, query_labels = get_query_slices_and_labels(query_volume_paths[0], query_label_paths[0], 1, sizeXY)\n",
    "\n",
    "model = universeg(pretrained=True)\n",
    "_ = model.to(device)\n",
    "\n",
    "n_predictions = query_slices.shape[0]\n",
    "\n",
    "scores = []\n",
    "\n",
    "# compute inference and save predictions and metrics for n_predictions\n",
    "\n",
    "for idx in tqdm(range(n_predictions)):\n",
    "    image, label = query_slices[idx], query_labels[idx]\n",
    "    score = inference_scored(model, image, label, support_slices, support_labels)\n",
    "    scores.append(score)\n",
    "\n",
    "print(sum(scores)/len(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkfz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
